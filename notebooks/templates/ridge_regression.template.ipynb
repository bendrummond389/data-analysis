{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "from scripts.database import get_session, load_data_to_db\n",
    "from scripts.utils import load_config, setup_logging\n",
    "from models import CarPriceDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = load_config()\n",
    "    setup_logging(config['paths']['log_path'])\n",
    "    logging.info(\"Starting the data analysis project.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load config or setup logging: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session = get_session()\n",
    "    logging.info(\"Database session created successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to create database session: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Car Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    car_price_data = session.query(CarPriceDataset).all()\n",
    "    data = [car.__dict__ for car in car_price_data]\n",
    "    for item in data:\n",
    "        item.pop('_sa_instance_state', None)\n",
    "    \n",
    "    car_price_df = pd.DataFrame(data)\n",
    "    print(car_price_df.head())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to query car price data: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group less frequent categories in 'model' and 'brand'\n",
    "model_counts = car_price_df['model'].value_counts()\n",
    "less_frequent_models = model_counts[model_counts < 10].index\n",
    "car_price_df['model'] = car_price_df['model'].apply(lambda x: 'Other' if x in less_frequent_models else x)\n",
    "\n",
    "brand_counts = car_price_df['brand'].value_counts()\n",
    "less_frequent_brands = brand_counts[brand_counts < 10].index\n",
    "car_price_df['brand'] = car_price_df['brand'].apply(lambda x: 'Other' if x in less_frequent_brands else x)\n",
    "\n",
    "# Create 'car_age' feature\n",
    "from datetime import datetime\n",
    "car_price_df['car_age'] = datetime.now().year - car_price_df['year']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['fuel_type', 'model', 'brand', 'transmission']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_categorical = encoder.fit_transform(car_price_df[categorical_cols])\n",
    "\n",
    "# Create DataFrame for encoded categorical variables\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Combine encoded categorical and numerical variables\n",
    "numerical_cols = car_price_df.drop(columns=categorical_cols + ['price', 'year'])\n",
    "X_encoded = pd.concat([numerical_cols.reset_index(drop=True), encoded_categorical_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = car_price_df['price']\n",
    "\n",
    "# Calculate mutual information\n",
    "mi = mutual_info_regression(X_encoded, y)\n",
    "\n",
    "# Create and display mutual information DataFrame\n",
    "mi_df = pd.DataFrame({'Feature': X_encoded.columns, 'Mutual Information': mi})\n",
    "mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "print(mi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Inflation Factor (VIF) Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for constant numerical columns\n",
    "constant_columns = [col for col in numerical_cols.columns if car_price_df[col].nunique() == 1]\n",
    "print(\"Constant columns:\", constant_columns)\n",
    "\n",
    "# Drop constant columns if any\n",
    "X_encoded_reduced = X_encoded.drop(columns=constant_columns)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_encoded_reduced.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_encoded_reduced.values, i) for i in range(len(X_encoded_reduced.columns))]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded_reduced)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of alpha values for Ridge Regression\n",
    "alphas = np.logspace(-4, 4, 50)  # Test alpha values from 10^-4 to 10^4\n",
    "\n",
    "# Use RidgeCV to find the best alpha\n",
    "ridge_cv = RidgeCV(alphas=alphas, store_cv_results=True)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "print(f\"Best alpha: {ridge_cv.alpha_}\")\n",
    "\n",
    "# Train Ridge Regression model with the best alpha\n",
    "ridge_model = Ridge(alpha=ridge_cv.alpha_)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
